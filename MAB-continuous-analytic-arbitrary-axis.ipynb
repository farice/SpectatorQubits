{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextual analytic geometric descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODOs\n",
    "\n",
    "* Outer loop plots.\n",
    "* \\>2 contexts, potentially with structure imposed.\n",
    "* Geometric descent (makes gradient updates independent of gate-parameterization).\n",
    "* Add gradient flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import scipy.interpolate\n",
    "\n",
    "from hyperopt import hp\n",
    "from collections import OrderedDict\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "\n",
    "from qutip import basis, expect\n",
    "from qutip.qip.operations import rx, rz\n",
    "\n",
    "from qutip.operators import sigmax\n",
    "from qutip.qip.operations import snot\n",
    "\n",
    "# Local imports\n",
    "from spectator_env_v2 import SpectatorEnvContinuousV2\n",
    "from spectator_env_utils_v2 import extract_theta_phi, plot, plot_layered, ParallelSimResult, get_error_unitary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_loss(meas, trans):\n",
    "    return np.var([np.pi - np.arccos(\n",
    "        np.sqrt(t.overlap(meas) * meas.overlap(t))) for t in trans])\n",
    "\n",
    "\n",
    "def correction_loss(meas, trans):\n",
    "    return np.mean([np.pi - np.arccos(\n",
    "        np.sqrt(t.overlap(meas) * meas.overlap(t))) for t in trans])\n",
    "\n",
    "\n",
    "# This is the contour of the \"true loss\" for correction and contextualization.\n",
    "def get_contour(error_samples, loss_fn, sensitivity=1.0):\n",
    "    prepared_basis = [snot() * basis(2, 0), snot() * sigmax() * basis(2, 0)]\n",
    "    trans = [get_error_unitary(sample, sensitivity) * prepared_basis[0]\n",
    "             for sample in error_samples]\n",
    "\n",
    "    thetas = np.linspace(0, np.pi, 33)\n",
    "    phis = np.linspace(-np.pi, np.pi, 33)\n",
    "    loss = np.zeros((len(thetas), len(phis)))\n",
    "\n",
    "    min_phi = 0.\n",
    "    min_theta = 0.\n",
    "    min_loss = 1.\n",
    "\n",
    "    max_phi = 0.\n",
    "    max_theta = 0.\n",
    "    max_loss = 0.\n",
    "    for i, theta in enumerate(thetas):\n",
    "        for j, phi in enumerate(phis):\n",
    "            meas = np.cos(theta / 2) * prepared_basis[0] + np.exp(\n",
    "                1j * phi) * np.sin(theta / 2) * prepared_basis[1]\n",
    "            meas = meas.unit()\n",
    "\n",
    "            objective = loss_fn(meas, trans)\n",
    "            if (np.abs(objective) < min_loss):\n",
    "                min_loss = objective\n",
    "                min_phi = phi\n",
    "                min_theta = theta\n",
    "            if (np.abs(objective) > max_loss):\n",
    "                max_loss = objective\n",
    "                max_phi = phi\n",
    "                max_theta = theta\n",
    "            loss[i][j] = np.abs(objective)\n",
    "    return {'thetas': thetas, 'phis': phis, 'loss': loss,\n",
    "            'max_phi': max_phi, 'max_theta': max_theta,\n",
    "            'min_phi': min_phi, 'min_theta': min_theta}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized action for a conditioning of the overall error distribution.\n",
    "class Context:\n",
    "    def __init__(self, gamma, eta, correction_theta_init):\n",
    "        # Discount factor.\n",
    "        # This parameter is deprecated given that we rely on gradient updates\n",
    "        # to adjust to non-stationarity.\n",
    "        self.gamma = gamma\n",
    "        # Gradient step size.\n",
    "        self.eta = eta\n",
    "\n",
    "        # Feedback which is batched until we decide to use it.\n",
    "        self.batch_correction_feedback = ([], [], [])\n",
    "        self.correction_theta = correction_theta_init\n",
    "\n",
    "        self.grads = [0, 0, 0]\n",
    "\n",
    "    def reset(self):\n",
    "        self.batch_correction_feedback = ([], [], [])\n",
    "\n",
    "    def discount(self):\n",
    "        pass\n",
    "\n",
    "    def update_gamma(self, gamma):\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def update_batch_feedback(self, correction_feedback, idx):\n",
    "        self.batch_correction_feedback[idx].append(correction_feedback)\n",
    "\n",
    "    def combine_correction_feedback(self):\n",
    "        # feedback is given per variational param\n",
    "        for idx, f in enumerate(self.batch_correction_feedback):\n",
    "            if len(f) == 0:\n",
    "                continue\n",
    "            lo = np.array([r[0] for r in f])\n",
    "            hi = np.array([r[1] for r in f])\n",
    "            lo = np.array(list(map(lambda x: -1 if x == 0 else 1, lo.flatten())))\n",
    "            hi = np.array(list(map(lambda x: -1 if x == 0 else 1, hi.flatten())))\n",
    "\n",
    "            mu_plus = np.mean(hi)\n",
    "            mu_minus = np.mean(lo)\n",
    "\n",
    "            grad = mu_plus - mu_minus\n",
    "\n",
    "            self.correction_theta[idx] -= self.eta * grad\n",
    "            self.grads[idx] = grad\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def get_optimal_params(self):\n",
    "        return self.correction_theta, self.grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contextual analytic geometric descent\n",
    "class Analytic2D:\n",
    "    def __init__(self, env, initial_gamma=1.0, context_eta=np.pi/64,\n",
    "                 correction_eta=np.pi/64, context_theta_init=[0, 0, 0],\n",
    "                 correction_theta_init=[[0, 0, 0], [0, 0, 0]]):\n",
    "        # Contexts are defined in terms of a function on spectator outcomes.\n",
    "        # Each context learns an optimal correction independently.\n",
    "        self.contexts = [Context(initial_gamma, correction_eta,\n",
    "                                 correction_theta_init[0]),\n",
    "                         Context(initial_gamma, correction_eta,\n",
    "                                 correction_theta_init[1])]\n",
    "\n",
    "        self.num_context_spectators = env.num_context_spectators\n",
    "\n",
    "        # step size\n",
    "        self.eta = context_eta\n",
    "\n",
    "        self.batch_context_feedback = ([], [], [])\n",
    "        self.context_theta = context_theta_init\n",
    "\n",
    "        self.grads = [0, 0, 0]\n",
    "\n",
    "    def get_actions(self, observations=None, batch_size=1):\n",
    "        # Our context is an array of binary spectator qubit measurements.\n",
    "        # Hence, we could convert this binary array to an integer and index\n",
    "        # 2^(spectator qubits) contexts.\n",
    "        # For now, we only have two contexts (+ vs -), and so we consider\n",
    "        # spectators to be indistinguishable noise polling devices.\n",
    "        # In the future, we may consider noise gradients and so we do indeed\n",
    "        # need to track the specific arrangement.\n",
    "\n",
    "        if observations is None:\n",
    "            return [{'context': self.context_theta} for i in range(batch_size)]\n",
    "\n",
    "        actions = []\n",
    "        for observation in observations:\n",
    "            context_idx = (1 if np.sum(observation) >\n",
    "                           self.num_context_spectators / 2 else 0)\n",
    "            context = self.contexts[context_idx]\n",
    "\n",
    "            optimal_correction, correction_grad = context.get_optimal_params()\n",
    "            actions.append(\n",
    "                {'correction': optimal_correction,\n",
    "                 'correction_grad': correction_grad,\n",
    "                 'context_grad': self.grads,\n",
    "                 'context': self.context_theta})\n",
    "        return actions\n",
    "\n",
    "    def combine_correction_feedback(self):\n",
    "        for context in self.contexts:\n",
    "            context.combine_correction_feedback()\n",
    "\n",
    "    def combine_contextual_feedback(self):\n",
    "        # Feedback is given per gate parameter.\n",
    "        for idx, f in enumerate(self.batch_context_feedback):\n",
    "            if len(f) == 0:\n",
    "                continue\n",
    "            lo = np.array([r[0] for r in f])\n",
    "            mid = np.array([r[1] for r in f])\n",
    "            hi = np.array([r[2] for r in f])\n",
    "\n",
    "            lo = np.array(list(map(lambda x: -1 if x == 0 else 1,\n",
    "                                   lo.flatten())))\n",
    "            mid = np.array(list(map(lambda x: -1 if x == 0 else 1,\n",
    "                                    mid.flatten())))\n",
    "            hi = np.array(list(map(lambda x: -1 if x == 0 else 1,\n",
    "                                   hi.flatten())))\n",
    "\n",
    "            mean_mid = np.mean(mid)\n",
    "            mean_lo = np.mean(lo)\n",
    "            mean_hi = np.mean(hi)\n",
    "            var_grad = np.mean([2 * (m - mean_mid)\n",
    "                                * ((h - l) - (mean_hi - mean_lo))\n",
    "                                for l, m, h in zip(lo, mid, hi)])\n",
    "            self.grads[idx] = var_grad\n",
    "\n",
    "            self.context_theta[idx] += self.eta * var_grad\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.batch_context_feedback = ([], [], [])\n",
    "\n",
    "    def update_correction_feedback(self, correction_feedback, observations):\n",
    "        # Feedback is given per variational param.\n",
    "        for idx in range(len(self.context_theta)):\n",
    "            for _correction_feedback, observation in zip(\n",
    "                    correction_feedback[idx], observations):\n",
    "                context_idx = (1 if np.sum(observation) >\n",
    "                               self.num_context_spectators / 2 else 0)\n",
    "                context = self.contexts[context_idx]\n",
    "                context.update_batch_feedback(_correction_feedback, idx)\n",
    "\n",
    "    def update_context_feedback(self, context_feedback, observations):\n",
    "        # Feedback is given per variational param.\n",
    "        for idx in range(len(self.context_theta)):\n",
    "            for _context_feedback, observation in zip(\n",
    "                    context_feedback[idx], observations):\n",
    "                self.batch_context_feedback[idx].append(_context_feedback)\n",
    "\n",
    "    def _update_gammas(self, gamma):\n",
    "        for context in self.contexts:\n",
    "            context.update_gamma(gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Hyperparameters\n",
    "'''\n",
    "\n",
    "\n",
    "# Spectators can used for two types of feedback:\n",
    "# (1) Improving the contextual conditioning.\n",
    "# (2) Improving the correction given each contextual conditioning.\n",
    "def feedback_spectators_allocation_function():\n",
    "    feedback_alloc = {}\n",
    "    feedback_alloc['correction'] = 2\n",
    "    feedback_alloc['context'] = 3\n",
    "#     feedback_alloc['correction'] = NUM_REWARD_SPECTATORS / 2\n",
    "#     feedback_alloc['context'] = (NUM_REWARD_SPECTATORS\n",
    "#                                  - feedback_alloc['correction'])\n",
    "    return feedback_alloc\n",
    "\n",
    "\n",
    "def error_samples_generator(mu, sigma, drift, iteration, batch_size):\n",
    "    # return np.random.choice([mu - sigma, mu + sigma], m)\n",
    "    # return list(zip(np.random.uniform(mu[0] - sigma[0], mu[0] + sigma[0], m),\n",
    "    #                 np.random.uniform(mu[1] - sigma[1], mu[1] + sigma[1], m)))\n",
    "    # return np.random.normal(MU, SIGMA, M) # + time_dependent_fn(np.arange(M))\n",
    "    direction = np.array([2, 1, 3])\n",
    "    mu += direction * iteration * drift\n",
    "    \n",
    "    return list(zip([np.random.normal(mu[0] + (iteration + i) * direction[0] * drift, sigma[0]) for i in range(batch_size)],\n",
    "                 [np.random.normal(mu[1] + (iteration + i) * direction[1] * drift, sigma[1]) for i in range(batch_size)], \n",
    "                [np.random.normal(mu[2] + (iteration + i) * direction[2] * drift, sigma[2]) for i in range(batch_size)]))\n",
    "\n",
    "\n",
    "# Total number of simultaneous measurements (time-steps) per epoch.\n",
    "# M = 64\n",
    "# Number of measurements (time-steps) per algorithm iteration.\n",
    "# For simplicity in presentation, it is recommended to match this to M.\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Number of epochs to run simulation.\n",
    "NUM_EPOCHS = 16\n",
    "# Total number of algorithm iterations until simulation completion.\n",
    "# (M // BATCH_SIZE) is the number of batches per epoch.\n",
    "MAX_FRAMES = NUM_EPOCHS # * M // BATCH_SIZE\n",
    "\n",
    "# Redraw error samples from potentially shifted distribution.\n",
    "NUM_EPOCHS_TO_REDRAW_ERRORS = 1\n",
    "\n",
    "# Error distribution.\n",
    "# May add some random harmonics.\n",
    "# time_dependent_fn = (np.vectorize(lambda x: (2/5) * np.pi\n",
    "#                      * np.sin(2 * np.pi * x / M)))\n",
    "MU_1 = 0\n",
    "SIGMA_1 = np.pi / 4\n",
    "MU_2 = 0\n",
    "SIGMA_2 = np.pi / 32\n",
    "MU_3 = 0\n",
    "SIGMA_3 = np.pi / 64\n",
    "# ERROR_SAMPLES = error_samples_generator([MU_1, MU_2, MU_3], [SIGMA_1, SIGMA_2, SIGMA_3], M)\n",
    "\n",
    "# Gradient step sizes.\n",
    "CONTEXT_ETA = np.pi / 16\n",
    "CORRECTION_ETA = np.pi / 16\n",
    "\n",
    "# Initialization of U3 Gates.\n",
    "CONTEXT_THETA_INIT = [0, 0, np.pi/4]\n",
    "CORRECTION_THETA_INIT = [[0, 0, 0], [0, 0, 0]]\n",
    "\n",
    "# Length of bit-string used to condition error distribution.\n",
    "NUM_CONTEXT_SPECTATORS = 3\n",
    "# Number of qubits available for measuring feedback w.r.t a desired objective.\n",
    "# Use a multiple of 12 for simplicity of analytic gradient computation.\n",
    "# Mod 12 requirement not actually necessary in practical setting.\n",
    "# NUM_REWARD_SPECTATORS = 60\n",
    "\n",
    "CONTEXT_SENSITIVITY = 1.0\n",
    "REWARD_SENSITIVITY = 1.0\n",
    "\n",
    "# Feedback is collected in batches, but variational parameters can be\n",
    "# updated after an arbitrary number of batches.\n",
    "NUM_BATCHES_TO_COMBINE_CONTEXT_FEEDBACK = 1\n",
    "NUM_BATCHES_TO_COMBINE_CORRECTION_FEEDBACK = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describes MDP\n",
    "# - states are given in terms of a #context_spectators bit measurement outcomes\n",
    "# - continuous action space is given by [-pi, pi]^3 single-qubit gate\n",
    "# parameterization.\n",
    "# env = SpectatorEnvContinuousV2(ERROR_SAMPLES, batch_size=BATCH_SIZE,\n",
    "#                                num_context_spectators=NUM_CONTEXT_SPECTATORS,\n",
    "#                                context_sensitivity=CONTEXT_SENSITIVITY,\n",
    "#                                reward_sensitivity=REWARD_SENSITIVITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context_contour = get_contour(ERROR_SAMPLES, context_loss)\n",
    "# print(context_contour['max_phi'], context_contour['max_theta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = timer()\n",
    "\n",
    "# md = Analytic2D(env, context_eta=CONTEXT_ETA,\n",
    "#                 correction_eta=CORRECTION_ETA,\n",
    "#                 context_theta_init=CONTEXT_THETA_INIT,\n",
    "#                 correction_theta_init=CORRECTION_THETA_INIT)\n",
    "\n",
    "\n",
    "# data_fidelity_per_episode = []\n",
    "# spectator_fidelity_per_episode = []\n",
    "# control_fidelity_per_episode = []\n",
    "# data_fidelity = []\n",
    "# spectator_fidelity = []\n",
    "# control_fidelity = []\n",
    "\n",
    "# # \"episodes\" are a reasonable way to think about learning a periodic\n",
    "# # time-dependent function.\n",
    "# # max frames = episode length * num episodes\n",
    "# # episodes are identical sequences of training data\n",
    "# init_actions = md.get_actions(batch_size=BATCH_SIZE)\n",
    "# observation = env.reset(init_actions)\n",
    "\n",
    "# correction_2d_repr = {}\n",
    "# context_2d_repr = []\n",
    "\n",
    "# correction_grads = {}\n",
    "# context_grads = []\n",
    "\n",
    "# # context outcomes per episode\n",
    "# context_outcome_hist = {}\n",
    "\n",
    "# batches_per_epoch = M // BATCH_SIZE\n",
    "# # Frames are given in terms of the number of batches of measurements.\n",
    "# for frame_idx in range(1, MAX_FRAMES + 1):\n",
    "#     # An epoch is a predefined number of batches: (M // BATCH_SIZE)\n",
    "#     epoch = frame_idx // batches_per_epoch\n",
    "\n",
    "#     '''\n",
    "#     Beginning of main logic.\n",
    "#     '''\n",
    "#     # This will return the known optimal actions as a function of the context\n",
    "#     # mapping.\n",
    "#     actions = md.get_actions(observation)\n",
    "#     prev_batch = np.array(env.error_samples_batch)\n",
    "#     prev_observation = observation\n",
    "\n",
    "#     # Allocation of non-contextual spectators between optimizing the objectives\n",
    "#     feedback_alloc = feedback_spectators_allocation_function()\n",
    "#     observation, feedback, done, info = env.step(actions, feedback_alloc)\n",
    "#     observation = None if done else observation\n",
    "\n",
    "#     md.update_correction_feedback(\n",
    "#               correction_feedback=feedback['batched_correction_feedback'],\n",
    "#               observations=prev_observation)\n",
    "#     md.update_context_feedback(\n",
    "#             context_feedback=feedback['batched_context_feedback'],\n",
    "#             observations=prev_observation)\n",
    "\n",
    "#     if frame_idx % NUM_BATCHES_TO_COMBINE_CORRECTION_FEEDBACK == 0:\n",
    "#         md.combine_correction_feedback()\n",
    "#     if frame_idx % NUM_BATCHES_TO_COMBINE_CONTEXT_FEEDBACK == 0:\n",
    "#         md.combine_contextual_feedback()\n",
    "\n",
    "#     if frame_idx % (NUM_EPOCHS_TO_REDRAW_ERRORS * batches_per_epoch) == 0:\n",
    "#         new_error_samples = error_samples_generator([MU_1, MU_2, MU_3], [SIGMA_1, SIGMA_2, SIGMA_3], M)\n",
    "#         env.set_error_samples(new_error_samples)\n",
    "\n",
    "#     '''\n",
    "#     End of main logic.\n",
    "#     '''\n",
    "\n",
    "#     for _info in info:\n",
    "#         data_fidelity.append(_info['data_fidelity'])\n",
    "#         if 'spectator_fidelity' in _info.keys():\n",
    "#             spectator_fidelity.append(_info['spectator_fidelity'])\n",
    "#         control_fidelity.append(_info['control_fidelity'])\n",
    "\n",
    "#     context_2d_repr.append(extract_theta_phi(\n",
    "#         env._get_correction(md.context_theta).dag()))\n",
    "#     for idx, c in enumerate(md.contexts):\n",
    "#         correction_2d = extract_theta_phi(\n",
    "#                 env._get_correction(c.correction_theta).dag())\n",
    "#         if idx in correction_2d_repr.keys():\n",
    "#             correction_2d_repr[idx].append(correction_2d)\n",
    "#         else:\n",
    "#             correction_2d_repr[idx] = [correction_2d]\n",
    "\n",
    "#     correction_grad = \\\n",
    "#         [np.mean([a['correction_grad'] for a in np.array(actions)[[\n",
    "#                 np.sum(obs) <= env.num_context_spectators / 2\n",
    "#                 for obs in prev_observation]]], axis=0),\n",
    "#          np.mean([a['correction_grad'] for a in np.array(actions)[[\n",
    "#                 np.sum(obs) > env.num_context_spectators / 2\n",
    "#                  for obs in prev_observation]]], axis=0)]\n",
    "#     for i in range(2):\n",
    "#         if np.isnan(np.sum(correction_grad[i])):\n",
    "#             continue\n",
    "#         if i in correction_grads.keys():\n",
    "#             correction_grads[i].append(correction_grad[i])\n",
    "#         else:\n",
    "#             correction_grads[i] = [correction_grad[i]]\n",
    "\n",
    "#     context_grads.append(np.mean(\n",
    "#         [a['context_grad'] for a in np.array(actions)], axis=0))\n",
    "\n",
    "#     for obs in prev_observation:\n",
    "#         context_outcome = \\\n",
    "#             1 if np.sum(obs) > env.num_context_spectators / 2 else 0\n",
    "#         if epoch in context_outcome_hist.keys():\n",
    "#             context_outcome_hist[epoch].append(context_outcome)\n",
    "#         else:\n",
    "#             context_outcome_hist[epoch] = [context_outcome]\n",
    "\n",
    "#     # All batches for episode complete.\n",
    "#     if done:\n",
    "#         data_fidelity_per_episode.append(np.mean(data_fidelity))\n",
    "#         if len(spectator_fidelity) > 0:\n",
    "#             spectator_fidelity_per_episode.append(np.mean(spectator_fidelity))\n",
    "#         control_fidelity_per_episode.append(np.mean(control_fidelity))\n",
    "#         data_fidelity = []\n",
    "#         spectator_fidelity = []\n",
    "#         control_fidelity = []\n",
    "\n",
    "#         correction_contour = {}\n",
    "#         correction_contour[0] = get_contour(prev_batch[\n",
    "#             [np.sum(obs) <= env.num_context_spectators / 2\n",
    "#              for obs in prev_observation]], correction_loss,\n",
    "#                                            sensitivity=REWARD_SENSITIVITY)\n",
    "#         correction_contour[1] = get_contour(prev_batch[\n",
    "#             [np.sum(obs) > env.num_context_spectators / 2\n",
    "#              for obs in prev_observation]], correction_loss,\n",
    "#                                            sensitivity=REWARD_SENSITIVITY)\n",
    "#         context_contour = get_contour(env.error_samples, context_loss,\n",
    "#                                       sensitivity=CONTEXT_SENSITIVITY)\n",
    "\n",
    "#         observation = env.reset(actions)\n",
    "\n",
    "#         clear_output(True)\n",
    "#         plot(frame_idx,\n",
    "#              timedelta(seconds=int(timer()-start)),\n",
    "#              baseline_fidelity=control_fidelity_per_episode,\n",
    "#              corrected_fidelity=data_fidelity_per_episode,\n",
    "#              spectator_fidelity=spectator_fidelity_per_episode,\n",
    "#              context_theta_history=context_2d_repr,\n",
    "#              correction_theta_history=correction_2d_repr,\n",
    "#              correction_contour=correction_contour,\n",
    "#              context_outcome_hist=context_outcome_hist,\n",
    "#              context_contour=context_contour,\n",
    "#              correction_grads=correction_grads,\n",
    "#              context_grads=context_grads)\n",
    "#         plt.show()\n",
    "\n",
    "# env.close()\n",
    "\n",
    "# print(\"Total runtime: \", timer()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelSim:\n",
    "    def __init__(self, context_eta, correction_eta, context_eta_init,\n",
    "                 correction_eta_init, batch_size, num_context_spectators,\n",
    "                 error_samples_generator, feedback_spectators_allocation_function,\n",
    "                 num_batches_to_combine_correction_feedback,\n",
    "                 num_batches_to_combine_context_feedback,\n",
    "                 num_epochs_to_redraw_errors):\n",
    "        # Should store all hyperparams so that config can be accessed readily in analysis.\n",
    "        self.context_eta = context_eta\n",
    "        self.correction_eta = correction_eta\n",
    "        self.context_eta_init = context_eta_init\n",
    "        self.correction_eta_init = correction_eta_init\n",
    "        self.batch_size = batch_size\n",
    "        self.num_context_spectators = num_context_spectators\n",
    "        self.error_samples_generator = error_samples_generator\n",
    "        self.feedback_spectators_allocation_function = feedback_spectators_allocation_function\n",
    "        self.num_batches_to_combine_correction_feedback = num_batches_to_combine_correction_feedback\n",
    "        self.num_batches_to_combine_context_feedback = num_batches_to_combine_context_feedback\n",
    "        self.num_epochs_to_redraw_errors = num_epochs_to_redraw_errors\n",
    "\n",
    "        error_samples = error_samples_generator(iteration=0, batch_size=self.batch_size)\n",
    "        self.env = SpectatorEnvContinuousV2(\n",
    "            error_samples, batch_size=batch_size,\n",
    "            num_context_spectators=num_context_spectators)\n",
    "        self.md = Analytic2D(self.env, context_eta=context_eta,\n",
    "                             correction_eta=correction_eta,\n",
    "                             context_theta_init=context_eta_init,\n",
    "                             correction_theta_init=correction_eta_init)\n",
    "        self.data_fidelity_per_episode = []\n",
    "        self.control_fidelity_per_episode = []\n",
    "        self.data_fidelity = []\n",
    "        self.control_fidelity = []\n",
    "        self.correction_2d_repr = {}\n",
    "        self.context_2d_repr = []\n",
    "        self.observation = self.env.reset(self.md.get_actions(\n",
    "                                          batch_size=batch_size))\n",
    "#         self.batches_per_epoch = M // batch_size\n",
    "        self.batches_per_epoch = 1\n",
    "        self.frame_idx = 0\n",
    "\n",
    "    def set_error_samples(self, new_error_samples):\n",
    "        self.env.set_error_samples(new_error_samples)\n",
    "\n",
    "    def step(self):\n",
    "        '''\n",
    "        Beginning of main logic.\n",
    "        '''\n",
    "\n",
    "        # This will return the known optimal actions as a function of the context\n",
    "        # mapping.\n",
    "        actions = self.md.get_actions(self.observation, batch_size=self.batch_size)\n",
    "        prev_batch = np.array(self.env.error_samples_batch)\n",
    "        prev_observation = self.observation\n",
    "\n",
    "        # Allocation of non-contextual spectators between optimizing the objectives\n",
    "        feedback_alloc = self.feedback_spectators_allocation_function()\n",
    "        self.observation, feedback, done, info = self.env.step(actions, feedback_alloc)\n",
    "        self.observation = None if done else self.observation\n",
    "\n",
    "        self.md.update_correction_feedback(\n",
    "                  correction_feedback=feedback['batched_correction_feedback'],\n",
    "                  observations=prev_observation)\n",
    "        self.md.update_context_feedback(\n",
    "                context_feedback=feedback['batched_context_feedback'],\n",
    "                observations=prev_observation)\n",
    "\n",
    "        if self.frame_idx % self.num_batches_to_combine_correction_feedback == 0:\n",
    "            self.md.combine_correction_feedback()\n",
    "        if self.frame_idx % self.num_batches_to_combine_context_feedback == 0:\n",
    "            self.md.combine_contextual_feedback()\n",
    "\n",
    "        if self.frame_idx % (self.num_epochs_to_redraw_errors * self.batches_per_epoch) == 0:\n",
    "            new_error_samples = self.error_samples_generator(iteration=self.frame_idx)\n",
    "            self.set_error_samples(new_error_samples)\n",
    "\n",
    "        '''\n",
    "        End of main logic.\n",
    "        '''\n",
    "\n",
    "        for _info in info:\n",
    "            self.data_fidelity.append(_info['data_fidelity'])\n",
    "            self.control_fidelity.append(_info['control_fidelity'])\n",
    "\n",
    "        self.context_2d_repr.append(extract_theta_phi(\n",
    "            self.env._get_correction(self.md.context_theta).dag()))\n",
    "        for idx, c in enumerate(self.md.contexts):\n",
    "            correction_2d = extract_theta_phi(\n",
    "                    self.env._get_correction(c.correction_theta).dag())\n",
    "            if idx in self.correction_2d_repr.keys():\n",
    "                self.correction_2d_repr[idx].append(correction_2d)\n",
    "            else:\n",
    "                self.correction_2d_repr[idx] = [correction_2d]\n",
    "\n",
    "        # All batches for episode complete.\n",
    "        if done:\n",
    "            self.data_fidelity_per_episode.append(np.mean(self.data_fidelity))\n",
    "            self.control_fidelity_per_episode.append(np.mean(self.control_fidelity))\n",
    "            self.data_fidelity = []\n",
    "            self.control_fidelity = []\n",
    "\n",
    "            self.observation = self.env.reset(actions)\n",
    "\n",
    "        self.frame_idx += 1\n",
    "        return ParallelSimResult(\n",
    "            done=done,\n",
    "            data_fidelity_per_episode=self.data_fidelity_per_episode,\n",
    "            control_fidelity_per_episode=self.control_fidelity_per_episode,\n",
    "            context_2d_repr=self.context_2d_repr,\n",
    "            correction_2d_repr=self.correction_2d_repr\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = timer()\n",
    "\n",
    "# num_sims = 4\n",
    "# num_repeats = 3\n",
    "# parallel_sims = []\n",
    "\n",
    "# # Error distribution should be made consistent between parallel simulations.\n",
    "# error_samples_generator_partial = functools.partial(\n",
    "#     error_samples_generator, [MU_1, MU_2, MU_3], [SIGMA_1, SIGMA_2, SIGMA_3], M, np.pi / 16)\n",
    "# for idx in range(num_sims):\n",
    "#     context_eta_init = np.random.uniform(-np.pi, np.pi, 3)\n",
    "#     correction_eta_init_1 = np.random.uniform(-np.pi, np.pi, 3)\n",
    "#     correction_eta_init_2 = np.random.uniform(-np.pi, np.pi, 3)\n",
    "#     rep = []\n",
    "#     for repeat in range(num_repeats):\n",
    "#         rep.append(\n",
    "#             ParallelSim(\n",
    "#                 context_eta=CONTEXT_ETA, correction_eta=CORRECTION_ETA,\n",
    "#                 context_eta_init=context_eta_init,\n",
    "#                 correction_eta_init=[correction_eta_init_1, correction_eta_init_2],\n",
    "#                 batch_size=BATCH_SIZE,\n",
    "#                 num_context_spectators=NUM_CONTEXT_SPECTATORS,\n",
    "#                 error_samples_generator=error_samples_generator_partial,\n",
    "#                 feedback_spectators_allocation_function=feedback_spectators_allocation_function,\n",
    "#                 # How we vary batch size for context vs. correction feedback gradients.\n",
    "#                 num_batches_to_combine_context_feedback=NUM_BATCHES_TO_COMBINE_CONTEXT_FEEDBACK,\n",
    "#                 num_batches_to_combine_correction_feedback=NUM_BATCHES_TO_COMBINE_CORRECTION_FEEDBACK,\n",
    "#                 num_epochs_to_redraw_errors=NUM_EPOCHS_TO_REDRAW_ERRORS)\n",
    "#         )\n",
    "#     parallel_sims.append(rep)\n",
    "\n",
    "# print(\"Repeats: \", num_repeats)\n",
    "# print(\"Epochs: \", NUM_EPOCHS)\n",
    "# for repeat in range(num_repeats):\n",
    "#     all_done = [False for p in parallel_sims]\n",
    "#     # results = {p: [] for p in parallel_sims}\n",
    "#     # results can be polled for specific hyperparams\n",
    "#     for epoch in range(NUM_EPOCHS):\n",
    "#         while not np.any(all_done):\n",
    "#             for i in range(len(parallel_sims)):\n",
    "#                 sim = parallel_sims[i][repeat]\n",
    "#                 if not all_done[i]:\n",
    "#                     r = sim.step()\n",
    "#                     all_done[i] = r.done\n",
    "#                     # Batch finished.\n",
    "#                     # if r.done:\n",
    "#                         # results[p] = np.append(results[p], r)\n",
    "#         all_done = [False for p in parallel_sims]\n",
    "#         print(f\"Completed epoch {epoch}, repeat {repeat}: \", timer() - start)\n",
    "\n",
    "# [p[i].env.close() for p in parallel_sims for i in range(num_repeats)]\n",
    "# print(\"Total runtime: \", timer()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch 0                                      \n",
      "8.701191087020561                                      \n",
      "Completed epoch 1                                      \n",
      "16.751281135017052                                     \n",
      "Completed epoch 2                                      \n",
      "24.81161285901908                                      \n",
      "Completed epoch 3                                      \n",
      "32.8545811700169                                       \n",
      "Completed epoch 4                                      \n",
      "40.88599745603278                                      \n",
      "Completed epoch 5                                      \n",
      "48.911757944035344                                     \n",
      "Completed epoch 6                                      \n",
      "57.01139402500121                                      \n",
      "Completed epoch 7                                      \n",
      "65.13073422398884                                      \n",
      "Completed epoch 8                                      \n",
      "73.26004695001757                                      \n",
      "Completed epoch 9                                      \n",
      "81.34550285700243                                      \n",
      "Completed epoch 10                                     \n",
      "89.38429621502291                                      \n",
      "Completed epoch 11                                     \n",
      "97.42173034104053                                      \n",
      "Completed epoch 12                                     \n",
      "105.51056240702746                                     \n",
      "Completed epoch 13                                     \n",
      "113.55786236200947                                     \n",
      "Completed epoch 14                                     \n",
      "121.75554063101299                                     \n",
      "Completed epoch 15                                     \n",
      "130.0839942690218                                      \n",
      "Completed epoch 0                                                                    \n",
      "133.19823110604193                                                                   \n",
      "Completed epoch 1                                                                    \n",
      "136.04148452100344                                                                   \n",
      "Completed epoch 2                                                                    \n",
      "138.85355557803996                                                                   \n",
      "Completed epoch 3                                                                    \n",
      "141.68924363900442                                                                   \n",
      "Completed epoch 4                                                                    \n",
      "144.49249358603265                                                                   \n",
      "Completed epoch 5                                                                    \n",
      "147.2848341090139                                                                    \n",
      "Completed epoch 6                                                                    \n",
      "150.0645507160225                                                                    \n",
      "Completed epoch 7                                                                    \n",
      "152.86058867600514                                                                   \n",
      "Completed epoch 8                                                                    \n",
      "155.6670138540212                                                                    \n",
      "Completed epoch 9                                                                    \n",
      "158.4605617680354                                                                    \n",
      "Completed epoch 10                                                                   \n",
      "161.26602616003947                                                                   \n",
      "Completed epoch 11                                                                   \n",
      "164.07421141199302                                                                   \n",
      "Completed epoch 12                                                                   \n",
      "166.87507599999662                                                                   \n",
      "Completed epoch 13                                                                   \n",
      "169.65368117199978                                                                   \n",
      "Completed epoch 14                                                                   \n",
      "172.4454053270165                                                                    \n",
      "Completed epoch 15                                                                   \n",
      "175.2810870790272                                                                    \n",
      "Completed epoch 0                                                                    \n",
      "191.89304272498703                                                                   \n",
      "Completed epoch 1                                                                    \n",
      "206.95951304899063                                                                   \n",
      "Completed epoch 2                                                                    \n",
      "221.97455707902554                                                                   \n",
      "Completed epoch 3                                                                    \n",
      "237.00084503099788                                                                   \n",
      "Completed epoch 4                                                                    \n",
      "252.1485305299866                                                                    \n",
      "Completed epoch 5                                                                    \n",
      "267.2357361000031                                                                    \n",
      "Completed epoch 6                                                                    \n",
      "282.4405100950389                                                                    \n",
      "Completed epoch 7                                                                    \n",
      "297.5126041659969                                                                    \n",
      "Completed epoch 8                                                                    \n",
      "312.5148572860053                                                                    \n",
      "Completed epoch 9                                                                    \n",
      "327.52102125500096                                                                   \n",
      "Completed epoch 10                                                                   \n",
      "342.49732670001686                                                                   \n",
      "Completed epoch 11                                                                   \n",
      "357.49989592604106                                                                   \n",
      "Completed epoch 12                                                                   \n",
      "372.7014431130374                                                                    \n",
      "Completed epoch 13                                                                   \n",
      "387.68952270701993                                                                   \n",
      "Completed epoch 14                                                                   \n",
      "402.815183120023                                                                     \n",
      "Completed epoch 15                                                                   \n",
      "418.2325380659895                                                                    \n",
      "Completed epoch 0                                                                    \n",
      "434.895473379991                                                                    \n",
      "Completed epoch 1                                                                   \n",
      "450.0524980840273                                                                   \n",
      "Completed epoch 2                                                                   \n",
      "465.1955765550374                                                                   \n",
      "Completed epoch 3                                                                   \n",
      "480.32086476898985                                                                  \n",
      "Completed epoch 4                                                                   \n",
      "495.629724694998                                                                    \n",
      "Completed epoch 5                                                                   \n",
      "510.893619029026                                                                    \n",
      "Completed epoch 6                                                                   \n",
      "526.0053493980085                                                                   \n",
      "Completed epoch 7                                                                   \n",
      "541.1312565390253                                                                   \n",
      "Completed epoch 8                                                                   \n",
      "556.5282190809958                                                                   \n",
      "Completed epoch 9                                                                   \n",
      "571.6408725010115                                                                   \n",
      "Completed epoch 10                                                                  \n",
      "586.769278996042                                                                    \n",
      "Completed epoch 11                                                                  \n",
      "601.8677915860317                                                                   \n",
      "Completed epoch 12                                                                  \n",
      "617.0025113149895                                                                   \n",
      "Completed epoch 13                                                                  \n",
      "632.1904515119968                                                                   \n",
      "  3%|▎         | 3/100 [10:32<3:56:13, 146.12s/trial, best loss: 0.2716492535340948]"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "\n",
    "\n",
    "parallel_sims_store = []\n",
    "\n",
    "def run_sim(context_eta, correction_eta, context_eta_init, correction_eta_init_1, correction_eta_init_2,\n",
    "           batch_size, num_context_spectators, error_samples_generator_partial, feedback_spectators_allocation_function,\n",
    "           num_batches_to_combine_context_feedback, num_batches_to_combine_correction_feedback, num_epochs_to_redraw_errors,\n",
    "           num_epochs, burnin_length):\n",
    "    parallel_sim = ParallelSim(\n",
    "                context_eta=context_eta, correction_eta=correction_eta,\n",
    "                context_eta_init=context_eta_init,\n",
    "                correction_eta_init=[correction_eta_init_1, correction_eta_init_2],\n",
    "                batch_size=batch_size,\n",
    "                num_context_spectators=num_context_spectators,\n",
    "                error_samples_generator=error_samples_generator_partial,\n",
    "                feedback_spectators_allocation_function=feedback_spectators_allocation_function,\n",
    "                # How we vary batch size for context vs. correction feedback gradients.\n",
    "                num_batches_to_combine_context_feedback=num_batches_to_combine_context_feedback,\n",
    "                num_batches_to_combine_correction_feedback=num_batches_to_combine_correction_feedback,\n",
    "                num_epochs_to_redraw_errors=num_epochs_to_redraw_errors)\n",
    "    all_done = False\n",
    "    # results = {p: [] for p in parallel_sims}\n",
    "    # results can be polled for specific hyperparams\n",
    "    for epoch in range(num_epochs):\n",
    "        while not all_done:\n",
    "            r = parallel_sim.step()\n",
    "            all_done = r.done\n",
    "        all_done = False\n",
    "        print(f\"Completed epoch {epoch}\", timer() - start)\n",
    "    parallel_sim.env.close()\n",
    "    data_fids = np.array(parallel_sim.data_fidelity_per_episode[burnin_length:])\n",
    "    ctrl_fids = np.array(parallel_sim.control_fidelity_per_episode[burnin_length:])\n",
    "    parallel_sims_store.append(parallel_sim)\n",
    "    return np.mean(data_fids - ctrl_fids, axis=0)\n",
    "\n",
    "\n",
    "run_sim_partial = functools.partial(\n",
    "    run_sim,\n",
    "    num_context_spectators=NUM_CONTEXT_SPECTATORS,\n",
    "    feedback_spectators_allocation_function=feedback_spectators_allocation_function,\n",
    "    num_batches_to_combine_context_feedback=NUM_BATCHES_TO_COMBINE_CONTEXT_FEEDBACK,\n",
    "    num_batches_to_combine_correction_feedback=NUM_BATCHES_TO_COMBINE_CORRECTION_FEEDBACK,\n",
    "    # Keep at 1.\n",
    "    num_epochs_to_redraw_errors=NUM_EPOCHS_TO_REDRAW_ERRORS,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    burnin_length=8\n",
    ")\n",
    "\n",
    "def objective(args):\n",
    "    context_eta_init = [args['context_eta_init_0'], args['context_eta_init_1'], args['context_eta_init_2']]\n",
    "    correction_eta_init_1 = [args['correction_eta_init_1_0'], args['correction_eta_init_1_1'], args['correction_eta_init_1_2']]\n",
    "    correction_eta_init_2 = [args['correction_eta_init_2_0'], args['correction_eta_init_2_1'], args['correction_eta_init_2_2']]\n",
    "    error_samples_generator_partial = functools.partial(\n",
    "        error_samples_generator, mu=[MU_1, MU_2, MU_3], sigma=[SIGMA_1, SIGMA_2, SIGMA_3], batch_size=args['batch_size'], drift=np.pi / 16)\n",
    "    return run_sim_partial(context_eta_init=context_eta_init,\n",
    "                           correction_eta_init_1=correction_eta_init_1,\n",
    "                           correction_eta_init_2=correction_eta_init_2,\n",
    "                           batch_size=args['batch_size'],\n",
    "                           correction_eta=args['correction_eta'],\n",
    "                           context_eta=args['context_eta'],\n",
    "                           error_samples_generator_partial=error_samples_generator_partial\n",
    "                          )\n",
    "\n",
    "# define a search space\n",
    "space = OrderedDict([('context_eta_init_0', hp.uniform('context_eta_init_0', \n",
    "                                                     -np.pi, np.pi)),\n",
    "                     ('context_eta_init_1', hp.uniform('context_eta_init_1', \n",
    "                                                     -np.pi, np.pi)),\n",
    "                     ('context_eta_init_2', hp.uniform('context_eta_init_2', \n",
    "                                                     -np.pi, np.pi)),\n",
    "                     ('correction_eta_init_1_0', hp.uniform('correction_eta_init_1_0', \n",
    "                                                     -np.pi, np.pi)),\n",
    "                     ('correction_eta_init_1_1', hp.uniform('correction_eta_init_1_1', \n",
    "                                                     -np.pi, np.pi)),\n",
    "                     ('correction_eta_init_1_2', hp.uniform('correction_eta_init_1_2', \n",
    "                                                     -np.pi, np.pi)),\n",
    "                     ('correction_eta_init_2_0', hp.uniform('correction_eta_init_2_0', \n",
    "                                                     -np.pi, np.pi)),\n",
    "                     ('correction_eta_init_2_1', hp.uniform('correction_eta_init_2_1', \n",
    "                                                     -np.pi, np.pi)),\n",
    "                     ('correction_eta_init_2_2', hp.uniform('correction_eta_init_2_2', \n",
    "                                                     -np.pi, np.pi)),\n",
    "                     ('batch_size', hp.randint('batch_size', 1, 128)),\n",
    "                     ('correction_eta', hp.loguniform('correction_eta', np.pi/128, np.pi/2)),\n",
    "                     ('context_eta', hp.loguniform('context_eta', np.pi/128, np.pi/2))\n",
    "                    ])\n",
    "\n",
    "# minimize the objective over the space\n",
    "from hyperopt import fmin, tpe, Trials\n",
    "best = fmin(objective, space, algo=tpe.suggest, max_evals=100)\n",
    "\n",
    "print(\"Total runtime: \", timer()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "dill.dump_session('notebook_env.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get contour over entire distribution. May need to subset for non-stationary case.\n",
    "context_contour = get_contour(error_samples_generator_partial(0), context_loss)\n",
    "optimal_phi, optimal_theta = context_contour['max_phi'], context_contour['max_theta']\n",
    "if optimal_phi > np.pi:\n",
    "    optimal_phi += np.pi\n",
    "\n",
    "\n",
    "# Allows plotting of conditioned correction contours according to the true\n",
    "# optimal conditioning. Previously, we conditioned based upon the current\n",
    "# estimator for conditioning.\n",
    "def condition_error_samples(error_samples, optimal_phi, optimal_theta):\n",
    "    polling_group = []\n",
    "    prepared_basis = [snot() * basis(2, 0), snot() * sigmax() * basis(2, 0)]\n",
    "    for e in error_samples:\n",
    "        u = get_error_unitary(e, sensitivity=1.0)\n",
    "        s = u * prepared_basis[0]\n",
    "        meas = np.cos(optimal_theta / 2) * prepared_basis[0] + np.exp(\n",
    "                1j * optimal_phi) * np.sin(optimal_theta / 2) * prepared_basis[1]\n",
    "        meas = meas.unit()\n",
    "        obj = np.real(meas.overlap(s) * s.overlap(meas))\n",
    "        polling_group.append(obj > 0.5)\n",
    "    return polling_group\n",
    "\n",
    "\n",
    "error_samples = np.array(error_samples_generator_partial(0))\n",
    "cond = np.array(condition_error_samples(error_samples, optimal_phi, optimal_theta))\n",
    "correction_contour = {}\n",
    "correction_contour[0] = get_contour(error_samples[\n",
    "    cond], correction_loss)\n",
    "correction_contour[1] = get_contour(error_samples[\n",
    "    ~cond], correction_loss)\n",
    "plot_layered(parallel_sims, context_contour, correction_contour, burnin_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "burnin_length = 10\n",
    "d = {\n",
    "    \"batch_number\": np.array([]),\n",
    "    \"context_eta_init\": np.array([]),\n",
    "    \"correction_eta_init_0\": np.array([]),\n",
    "    \"correction_eta_init_1\": np.array([]),\n",
    "    \"relative_fid\": np.array([])\n",
    "}\n",
    "for idx, sim in enumerate(parallel_sims):\n",
    "        data_fids = np.mean(np.array([s.data_fidelity_per_episode[burnin_length:] for s in sim]), axis=0)\n",
    "        ctrl_fids = np.mean(np.array([s.control_fidelity_per_episode[burnin_length:] for s in sim]), axis=0)\n",
    "        \n",
    "        rel_fids = data_fids / ctrl_fids\n",
    "        for i, r in enumerate(rel_fids):\n",
    "            d[\"batch_number\"] = np.append(d[\"batch_number\"], i)\n",
    "            d[\"relative_fid\"] = np.append(d[\"relative_fid\"], r)\n",
    "            d[\"context_eta_init\"] = np.append(d[\"context_eta_init\"], sim[0].context_eta_init[0])\n",
    "            d[\"correction_eta_init_0\"] = np.append(d[\"correction_eta_init_0\"], sim[0].correction_eta_init[0][0])\n",
    "            d[\"correction_eta_init_1\"] = np.append(d[\"correction_eta_init_1\"], sim[0].correction_eta_init[1][0])\n",
    "        \n",
    "        \n",
    "df = pd.DataFrame.from_dict(d)\n",
    "g = sns.relplot(\n",
    "    data=df,\n",
    "    x=\"context_eta_init\", y=\"correction_eta_init_0\", hue=\"relative_fid\", size=\"relative_fid\"\n",
    ")\n",
    "\n",
    "# Tweak the figure to finalize\n",
    "g.set(xlabel=\"\", ylabel=\"\", aspect=\"equal\")\n",
    "g.despine(left=True, bottom=True)\n",
    "g.ax.margins(.02)\n",
    "for label in g.ax.get_xticklabels():\n",
    "    label.set_rotation(90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rz(np.pi / 2) * snot() * basis(2, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix breakdowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytic_context_grad(meas_lo, meas_mid, meas_hi, trans):\n",
    "    lo = np.array(\n",
    "        [np.sqrt(t.overlap(meas_lo) * meas_lo.overlap(t)) for t in trans])\n",
    "    mid = np.array(\n",
    "        [np.sqrt(t.overlap(meas_mid) * meas_mid.overlap(t)) for t in trans])\n",
    "    hi = np.array(\n",
    "        [np.sqrt(t.overlap(meas_hi) * meas_hi.overlap(t)) for t in trans])\n",
    "\n",
    "    mean_mid = np.mean(mid)\n",
    "    mean_lo = np.mean(lo)\n",
    "    mean_hi = np.mean(hi)\n",
    "    var_grad = np.mean([2 * (m - mean_mid) * ((h - l) - (mean_hi - mean_lo))\n",
    "                        for l, m, h in zip(lo, mid, hi)])\n",
    "    return var_grad\n",
    "\n",
    "\n",
    "# This is the contour of the *gradient* we actually compute using\n",
    "# parameter-shift-measurable observables. Spectator qubits achieve a finite\n",
    "# sampling of this expectation value.\n",
    "def get_analytic_contour(error_samples, num_variational_params=11):\n",
    "    prepared_basis = [snot() * basis(2, 0), snot() * sigmax() * basis(2, 0)]\n",
    "    trans = [rz(sample) * prepared_basis[0] for sample in error_samples]\n",
    "\n",
    "    variational_params = np.linspace(-np.pi, np.pi - (np.pi/128),\n",
    "                                     num_variational_params)\n",
    "    theta_phi_feedback = {}\n",
    "\n",
    "    for t_1 in variational_params:\n",
    "        for t_2 in variational_params:\n",
    "            for t_3 in variational_params:\n",
    "                t = [t_1, t_2, t_3]\n",
    "                unitary_mid = (rz(t[2]) * rx(-np.pi/2) * rz(t[1]) *\n",
    "                               rx(np.pi / 2) * rz(t[0]))\n",
    "\n",
    "                theta_mid, phi_mid = extract_theta_phi(unitary_mid.dag())\n",
    "                meas_mid = (np.cos(theta_mid / 2) * prepared_basis[0] + np.exp(\n",
    "                    1j * phi_mid) * np.sin(theta_mid / 2) * prepared_basis[1])\n",
    "                meas_mid = meas_mid.unit()\n",
    "\n",
    "                if (theta_mid, phi_mid) in theta_phi_feedback.keys():\n",
    "                    continue\n",
    "\n",
    "                g = []\n",
    "                for i in range(3):\n",
    "                    t[i] += -np.pi / 2\n",
    "                    unitary_lo = (rz(t[2]) * rx(-np.pi/2) * rz(t[1]) *\n",
    "                                  rx(np.pi / 2) * rz(t[0]))\n",
    "                    t[i] += np.pi\n",
    "                    unitary_hi = (rz(t[2]) * rx(-np.pi/2) * rz(t[1]) *\n",
    "                                  rx(np.pi / 2) * rz(t[0]))\n",
    "                    t[i] += -np.pi / 2\n",
    "\n",
    "                    theta_lo, phi_lo = extract_theta_phi(unitary_lo.dag())\n",
    "                    theta_hi, phi_hi = extract_theta_phi(unitary_hi.dag())\n",
    "\n",
    "                    meas_lo = (np.cos(theta_lo / 2) * prepared_basis[0]\n",
    "                               + np.exp(1j * phi_lo) * np.sin(theta_lo / 2)\n",
    "                               * prepared_basis[1]).unit()\n",
    "                    meas_hi = (np.cos(theta_hi / 2) * prepared_basis[0]\n",
    "                               + np.exp(1j * phi_hi) * np.sin(theta_hi / 2)\n",
    "                               * prepared_basis[1]).unit()\n",
    "\n",
    "                    g.append(analytic_context_grad(meas_lo=meas_lo,\n",
    "                                                   meas_mid=meas_mid,\n",
    "                                                   meas_hi=meas_hi,\n",
    "                                                   trans=trans))\n",
    "\n",
    "                theta_phi_feedback[(round(theta_mid, 2),\n",
    "                                    round(phi_mid, 2))] = np.linalg.norm(g)\n",
    "\n",
    "    theta_grid = []\n",
    "    phi_grid = []\n",
    "    feedback = []\n",
    "\n",
    "    for (t, p), f in theta_phi_feedback.items():\n",
    "        theta_grid.append(t)\n",
    "        phi_grid.append(p)\n",
    "        feedback.append(f)\n",
    "    theta_grid = np.array(theta_grid)\n",
    "    phi_grid = np.array(phi_grid)\n",
    "    mesh_theta = mesh_phi = np.linspace(-np.pi, np.pi,\n",
    "                                        len(variational_params ** 3))\n",
    "    mesh_theta, mesh_phi = np.meshgrid(mesh_theta, mesh_phi)\n",
    "\n",
    "    # Interpolate using radial basis kernel.\n",
    "    rbf = scipy.interpolate.Rbf(theta_grid, phi_grid, feedback,\n",
    "                                function='linear')\n",
    "    loss = rbf(mesh_theta, mesh_phi)\n",
    "\n",
    "    return {'mesh_phi': mesh_phi, 'mesh_theta': mesh_theta, 'loss': loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is very slow. O(n^3) computation, for n=num_variational_params.\n",
    "# context_analytic_contour = get_analytic_contour(ERROR_SAMPLES,\n",
    "#                                                 num_variational_params=15)\n",
    "# print(len(context_analytic_contour['mesh_phi']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, a = plt.subplots(1, 1, figsize=(7.5, 7.5), subplot_kw=dict(polar=True))\n",
    "CS = a.contourf(context_analytic_contour['mesh_phi'],\n",
    "                context_analytic_contour['mesh_theta'],\n",
    "                context_analytic_contour['loss'])\n",
    "a.scatter(x=[np.pi/2], y=[np.pi/2], label='ideal')\n",
    "# a.clabel(CS, inline=True, fontsize=14, colors='r',\n",
    "#          manual=[(-np.pi/2, np.pi/2)])\n",
    "a.legend()\n",
    "a.set_title(\"True analytic context gradient magnitude\")\n",
    "\n",
    "cbar = f.colorbar(CS)\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
